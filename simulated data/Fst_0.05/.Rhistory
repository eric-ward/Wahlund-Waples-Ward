# loop over all data
SR[i] ~ dnorm(x[DIST[i],1,1], tauResid1);
#SRV[i] ~ dnorm(x[DIST[i],2,d[ID[i]]], tauResid2);
}
}
", file = "model.txt")
jags.model = jags(jags.data, inits = NULL, parameters.to.save= jags.params, model.file=model.loc, n.chains = mcmc.chains, n.burnin = mcmc.burn, n.thin = mcmc.thin, n.iter = mcmc.chainLength, DIC = TRUE)
model = cat("
model {
# indices on x are time, Sr/SrV, group
# prior on initial state for Sr
x[1,1,1] ~dnorm(0,1);
x[1,2,1]~ dnorm(0,1);
# prior on initial state for Srv
x[1,1,2] ~dnorm(0,1);
x[1,2,2]~ dnorm(0,1);
# priors for covariance matrices
d2[1,1]<-1;
d2[1,2]<-0;
d2[2,1]<-0;
d2[2,2]<-1;
# unique cov matrix by group
tau1[1:2,1:2]~dwish(d2[1:2,1:2],2);
tau2[1:2,1:2]~dwish(d2[1:2,1:2],2);
for(i in 2:102) {
# random walks in isotopic space / SrV space
x[i,1:2,1] ~ dmnorm(x[i-1,1:2,1],tau1);
x[i,1:2,2] ~ dmnorm(x[i-1,1:2,2],tau2);
}
# Treat membership of each group as latent state
# this only models fish not assigned to ref pop
alpha[1]<-1;
alpha[2]<-1;
p[1:2]~ddirch(alpha[1:2]);
for(i in 1:190) {
d[i]~dcat(p[1:2]);
}
# Likelihood of all data
tauResid1 ~ dgamma(0.001,0.001);
tauResid2 ~ dgamma(0.001,0.001);
for(i in 1:N) {
# loop over all data
SR[i] ~ dnorm(x[DIST[i],1,d[ID[i]]], tauResid1);
SRV[i] ~ dnorm(x[DIST[i],2,d[ID[i]]], tauResid2);
}
}
", file = "model.txt")
jags.model = jags(jags.data, inits = NULL, parameters.to.save= jags.params, model.file=model.loc, n.chains = mcmc.chains, n.burnin = mcmc.burn, n.thin = mcmc.thin, n.iter = mcmc.chainLength, DIC = TRUE)
ID
max(ID)
model = cat("
model {
# indices on x are time, Sr/SrV, group
# prior on initial state for Sr
x[1,1,1] ~dnorm(0,1);
x[1,2,1]~ dnorm(0,1);
# prior on initial state for Srv
x[1,1,2] ~dnorm(0,1);
x[1,2,2]~ dnorm(0,1);
# priors for covariance matrices
d2[1,1]<-1;
d2[1,2]<-0;
d2[2,1]<-0;
d2[2,2]<-1;
# unique cov matrix by group
tau1[1:2,1:2]~dwish(d2[1:2,1:2],2);
tau2[1:2,1:2]~dwish(d2[1:2,1:2],2);
for(i in 2:102) {
# random walks in isotopic space / SrV space
x[i,1:2,1] ~ dmnorm(x[i-1,1:2,1],tau1);
x[i,1:2,2] ~ dmnorm(x[i-1,1:2,2],tau2);
}
# Treat membership of each group as latent state
# this only models fish not assigned to ref pop
alpha[1]<-1;
alpha[2]<-1;
p[1:2]~ddirch(alpha[1:2]);
for(i in 1:192) {
d[i]~dcat(p[1:2]);
}
# Likelihood of all data
tauResid1 ~ dgamma(0.001,0.001);
tauResid2 ~ dgamma(0.001,0.001);
for(i in 1:N) {
# loop over all data
SR[i] ~ dnorm(x[DIST[i],1,d[ID[i]]], tauResid1);
SRV[i] ~ dnorm(x[DIST[i],2,d[ID[i]]], tauResid2);
}
}
", file = "model.txt")
jags.model = jags(jags.data, inits = NULL, parameters.to.save= jags.params, model.file=model.loc, n.chains = mcmc.chains, n.burnin = mcmc.burn, n.thin = mcmc.thin, n.iter = mcmc.chainLength, DIC = TRUE)
attach.jags(jags.model)
dim(d)
apply(d,2,mean)
apply(d-1,2,mean)
hist(apply(d-1,2,mean))
apply(d,2,sd)
Group1 = unique(oto$fishYear[which(oto$isAR==0)])
n1 = length(Group1)
Group2 = unique(oto$fishYear[which(oto$isAR==1)])
n2 = length(Group2)
n1
n2
Group1
Group2
oto$fishYearNum = as.numeric(oto$fishYear) # creates fish ID
Group1 = unique(oto$fishYearNum[which(oto$isAR==0)])
n1 = length(Group1)
Group2 = unique(oto$fishYearNum[which(oto$isAR==1)])
n2 = length(Group2)
n1
n2
Group1
Group2
oto$fishYearNum = as.numeric(oto$fishYear) # creates fish ID
Group1 = unique(oto$fishYearNum[which(oto$isAR==0)])
n1 = length(Group1)
Group2 = unique(oto$fishYearNum[which(oto$isAR==1)])
n2 = length(Group2)
GroupU = unique(oto$fishYearNum[which(is.na(oto$isAR))])
nU = length(GroupU)
mcmc.chainLength <- as.integer(30000)# burn-in plus post-burn
mcmc.burn <- as.integer(20000)
mcmc.thin = 10
mcmc.chains = 4# needs to be at least 2 for DIC
jags.data = list("N","SR","SRV","DIST","ID","Group1","n1",
"Group2","n2","GroupU","nU")
jags.params=c("d")
model = cat("
model {
# indices on x are time, Sr/SrV, group
# prior on initial state for Sr
x[1,1,1] ~dnorm(0,1);
x[1,2,1]~ dnorm(0,1);
# prior on initial state for Srv
x[1,1,2] ~dnorm(0,1);
x[1,2,2]~ dnorm(0,1);
# priors for covariance matrices
d2[1,1]<-1;
d2[1,2]<-0;
d2[2,1]<-0;
d2[2,2]<-1;
# unique cov matrix by group
tau1[1:2,1:2]~dwish(d2[1:2,1:2],2);
tau2[1:2,1:2]~dwish(d2[1:2,1:2],2);
for(i in 2:102) {
# random walks in isotopic space / SrV space
x[i,1:2,1] ~ dmnorm(x[i-1,1:2,1],tau1);
x[i,1:2,2] ~ dmnorm(x[i-1,1:2,2],tau2);
}
# Treat membership of each group as latent state
# this only models fish not assigned to ref pop
alpha[1]<-1;
alpha[2]<-1;
p[1:2]~ddirch(alpha[1:2]);
for(i in 1:n1) {
d[Group1[i]]<-1;
}
for(i in 1:n2) {
d[Group2[i]]<-2;
}
for(i in 1:nU) {
d[GroupU[i]]~dcat(p[1:2]);
}
# Likelihood of all data
tauResid1 ~ dgamma(0.001,0.001);
tauResid2 ~ dgamma(0.001,0.001);
for(i in 1:N) {
# loop over all data
SR[i] ~ dnorm(x[DIST[i],1,d[ID[i]]], tauResid1);
SRV[i] ~ dnorm(x[DIST[i],2,d[ID[i]]], tauResid2);
}
}
", file = "model.txt")
mcmc.chainLength <- as.integer(30000)# burn-in plus post-burn
mcmc.burn <- as.integer(20000)
mcmc.thin = 10
mcmc.chains = 4# needs to be at least 2 for DIC
jags.data = list("N","SR","SRV","DIST","ID","Group1","n1",
"Group2","n2","GroupU","nU")
jags.params=c("d")
model.loc = paste("model.txt",sep="")
jags.model = jags(jags.data, inits = NULL, parameters.to.save= jags.params, model.file=model.loc, n.chains = mcmc.chains, n.burnin = mcmc.burn, n.thin = mcmc.thin, n.iter = mcmc.chainLength, DIC = TRUE)
jags.params
mcmc.chainLength <- as.integer(3000)# burn-in plus post-burn
mcmc.burn <- as.integer(2000)
mcmc.thin = 10
mcmc.chains = 2# needs to be at least 2 for DIC
jags.data = list("N","SR","SRV","DIST","ID","Group1","n1",
"Group2","n2","GroupU","nU")
jags.params=c("d","tauResid1","tauResid2")
model.loc = paste("model.txt",sep="")
jags.model = jags(jags.data, inits = NULL, parameters.to.save= jags.params, model.file=model.loc, n.chains = mcmc.chains, n.burnin = mcmc.burn, n.thin = mcmc.thin, n.iter = mcmc.chainLength, DIC = TRUE)
model = cat("
model {
# indices on x are time, Sr/SrV, group
# prior on initial state for Sr
x[1,1,1] ~dnorm(0,1);
x[1,2,1]~ dnorm(0,1);
# prior on initial state for Srv
x[1,1,2] ~dnorm(0,1);
x[1,2,2]~ dnorm(0,1);
# priors for covariance matrices
d2[1,1]<-1;
d2[1,2]<-0;
d2[2,1]<-0;
d2[2,2]<-1;
# unique cov matrix by group
tau1[1:2,1:2]~dwish(d2[1:2,1:2],2);
tau2[1:2,1:2]~dwish(d2[1:2,1:2],2);
for(i in 2:102) {
# random walks in isotopic space / SrV space
x[i,1:2,1] ~ dmnorm(x[i-1,1:2,1],tau1);
x[i,1:2,2] ~ dmnorm(x[i-1,1:2,2],tau2);
}
# Treat membership of each group as latent state
# this only models fish not assigned to ref pop
alpha[1]<-1;
alpha[2]<-1;
p[1:2]~ddirch(alpha[1:2]);
for(i in 1:n1) {
d[Group1[i]]<-1;
}
for(i in 1:n2) {
d[Group2[i]]<-2;
}
for(i in 1:nU) {
d[GroupU[i]]~dcat(p[1:2]);
z[i]<-d[GroupU[i]];
}
# Likelihood of all data
tauResid1 ~ dgamma(0.001,0.001);
tauResid2 ~ dgamma(0.001,0.001);
for(i in 1:N) {
# loop over all data
SR[i] ~ dnorm(x[DIST[i],1,d[ID[i]]], tauResid1);
SRV[i] ~ dnorm(x[DIST[i],2,d[ID[i]]], tauResid2);
}
}
", file = "model.txt")
mcmc.chainLength <- as.integer(3000)# burn-in plus post-burn
mcmc.burn <- as.integer(2000)
mcmc.thin = 10
mcmc.chains = 2# needs to be at least 2 for DIC
jags.data = list("N","SR","SRV","DIST","ID","Group1","n1",
"Group2","n2","GroupU","nU")
jags.params=c("z","tauResid1","tauResid2")
jags.model = jags(jags.data, inits = NULL, parameters.to.save= jags.params, model.file=model.loc, n.chains = mcmc.chains, n.burnin = mcmc.burn, n.thin = mcmc.thin, n.iter = mcmc.chainLength, DIC = TRUE)
attach.jags(jags.model)
dim(z)
apply(z,1,mean)
apply(z-1,1,mean)
dim(z)
apply(z-1,2,mean)
hist(apply(z-1,2,mean))
mcmc.chainLength <- as.integer(50000)# burn-in plus post-burn
mcmc.burn <- as.integer(40000)
mcmc.thin = 10
mcmc.chains = 4# needs to be at least 2 for DIC
jags.data = list("N","SR","SRV","DIST","ID","Group1","n1",
"Group2","n2","GroupU","nU")
jags.params=c("z","tauResid1","tauResid2")
model.loc = paste("model.txt",sep="")
jags.model = jags(jags.data, inits = NULL, parameters.to.save= jags.params, model.file=model.loc, n.chains = mcmc.chains, n.burnin = mcmc.burn, n.thin = mcmc.thin, n.iter = mcmc.chainLength, DIC = TRUE)
attach.jags(model)
attach.jags(jags.model)
dim(z)
apply(z,1,mean)
apply(z-1,1,mean)
hist(apply(z-1,1,mean))
mcmc.chainLength <- as.integer(100000)# burn-in plus post-burn
mcmc.burn <- as.integer(90000)
mcmc.thin = 10
mcmc.chains = 4# needs to be at least 2 for DIC
jags.data = list("N","SR","SRV","DIST","ID","Group1","n1",
"Group2","n2","GroupU","nU")
jags.params=c("z","tauResid1","tauResid2")
model.loc = paste("model.txt",sep="")
jags.model = jags(jags.data, inits = NULL, parameters.to.save= jags.params, model.file=model.loc, n.chains = mcmc.chains, n.burnin = mcmc.burn, n.thin = mcmc.thin, n.iter = mcmc.chainLength, DIC = TRUE)
attach.jags(jags.model)
hist(apply(z-1,1,mean))
which(apply(z-1,1,mean)>0.75)
which(apply(z-1,1,mean)>0.75)
apply(z-1,1,mean)
dim(apply(z-1,1,mean))
dim(apply(z-1,2,mean))
apply(z-1,2,mean)
hist(apply(z-1,2,mean))
which(apply(z-1,2,mean)<0.25)
which(apply(z-1,2,mean)>0.75)
mcmc.chainLength <- as.integer(1000)# burn-in plus post-burn
mcmc.burn <- as.integer(900)
mcmc.thin = 10
mcmc.chains = 4# needs to be at least 2 for DIC
jags.data = list("N","SR","SRV","DIST","ID","Group1","n1",
"Group2","n2","GroupU","nU")
jags.params=c("z","tauResid1","tauResid2")
model.loc = paste("model.txt",sep="")
indx
indx = which(is.na(oto$isAR))# Do American River classification
indx
which(is.na(oto$isAR))
?svm
model <- svm(Species ~ ., data = iris)
data(iris)
iris
class(iris)
x <- subset(iris, select = -Species)
y <- Species
x
data(iris)
attach(iris)
## classification mode
# default with factor response:
model <- svm(Species ~ ., data = iris)
# alternatively the traditional interface:
x <- subset(iris, select = -Species)
y <- Species
x
class(x)
x[1,1]
x[1,1]=NA
model <- svm(x, y)
model
indx = which(is.na(oto$isAR))
indx = which(is.na(oto$isAR))# Do American River classification
# Build a 2 new matrices where fish are on rows and Sr or SrV are
# across columns. Like the Bayesian model below, round distance into
# 10-micron bins
oto$micron10 = round(oto$radius_in_microns/10)
oro$micron10
oto$micron10
names(oto)
oto$fishYearNum
max(oto$micron10)
SrMat = matrix(NA, max(oto$fishYearNum), max(oto$micron10))
for(i in 1:max(oto$fishYearNum)) {
for(j in 1:max(oto$micron10)) {
indx = which(oto$fishYearNum == i & oto$micron10 == j)
if(length(indx)>0) {
SrMat[i,j] = oto$otoSr[indx]
}
}
}
indx
indx
oto$micron10 = round(oto$radius_in_microns/10)
SrMat = matrix(NA, max(oto$fishYearNum), max(oto$micron10))
for(i in 1:max(oto$fishYearNum)) {
for(j in 1:max(oto$micron10)) {
indx = which(oto$fishYearNum == i & oto$micron10 == j)
if(length(indx)>0) {
SrMat[i,j] = oto$otoSr[indx[1]]
}
}
}
SrMat = matrix(NA, max(oto$fishYearNum), max(oto$micron10))
for(i in 1:max(oto$fishYearNum)) {
for(j in 1:max(oto$micron10)) {
indx = which(oto$fishYearNum == i & oto$micron10 == j)
if(length(indx)>0) {
SrMat[i,j] = mean(oto$otoSr[indx])
}
}
}
oto$fishYearNum
SrMat
dim(SrMar)
dim(SrMat)
head(SrMat)
apply(SrMat,1,mean,na.rm=T)
SrMat=data.frame(SrMat, names = paste(Sr,seq(1,max(oto$micron10))))
SrMat=data.frame(SrMat, names = paste("Sr",seq(1,max(oto$micron10))))
SrMat=data.frame(SrMat, names = paste("Sr",seq(1,max(oto$micron10))))
SrMat
?data.frame
SrMat=data.frame(SrMat, col.names = paste("Sr",seq(1,max(oto$micron10))))
SrMat=data.frame(SrMat)
names(SrMat)
SrMat=data.frame(SrMat)
names(SrMat) = paste("Sr",seq(1,max(oto$micron10)))
names(SrMat)
xMat=data.frame(cbind(SrMat,SrVMat))
oto$micron10 = round(oto$radius_in_microns/10)
SrMat = matrix(NA, max(oto$fishYearNum), max(oto$micron10))
SrVMat = matrix(NA, max(oto$fishYearNum), max(oto$micron10))
for(i in 1:max(oto$fishYearNum)) {
for(j in 1:max(oto$micron10)) {
indx = which(oto$fishYearNum == i & oto$micron10 == j)
if(length(indx)>0) {
SrMat[i,j] = mean(oto$otoSr[indx])
SrVMat[i,j] = mean(oto$otoSr[indx])
}
}
}
xMat=data.frame(cbind(SrMat,SrVMat))
xMat=data.frame(cbind(SrMat,SrVMat))
names(xMat) = c(paste("Sr",seq(1,max(oto$micron10)),sep=""),
paste("SrV",seq(1,max(oto$micron10)),sep=""))
xMat
dim(xMat)
table(oto$isAR,oto$FishYearNum)
names(oto)
table(oto$isAR,oto$fishYearNum)
table(oto$isAR,oto$fishYearNum)[2,]
table(oto$isAR,oto$fishYearNum)[2,]==1
which(table(oto$isAR,oto$fishYearNum)[2,]==1)
which(table(oto$isAR,oto$fishYearNum)[2,]==1)
table(oto$isAR,oto$fishYearNum)[2,]
which(table(oto$isAR,oto$fishYearNum)[2,]>0)
names(which(table(oto$isAR,oto$fishYearNum)[2,]>0))
as.numeric(names(which(table(oto$isAR,oto$fishYearNum)[2,]>0)))
dim(xMat)[1]
y = rep(NA, dim(xMat)[1])
y = rep(NA, dim(xMat)[1])
y[as.numeric(names(which(table(oto$isAR,oto$fishYearNum)[2,]>0)))]=1
y[as.numeric(names(which(table(oto$isAR,oto$fishYearNum)[1,]>0)))]=0
as.numeric(names(which(table(oto$isAR,oto$fishYearNum)[2,]>0)))
y
indx = which(is.na(y)==FALSE)
indx
y.train = as.factor(y[indx])
x.train = xMat[indx,]
length(indx)
x.train
dim(x.train)
xMat$group = as.factor(y)
svm.model <- svm(group ~ .,
data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
svm.model <- svm(group ~ xMat[,1],
data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
xMat$group
xMat[indx,]
xMat[indx,]
svm.model <- svm(group ~ xMat[,1],data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
names(xMat)
svm.model <- svm(group ~ SrV97,data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
svm.model <- svm(group ~ SrV1,data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
svm.model <- svm(group ~ .,data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
svm.model <- svm(group ~ .,data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
group
group
group
group
group
xMat$group
svm.model <- svm(xMat$group[indx] ~ .,data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
svm.model <- svm(xMat$group[indx] ~ .,data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
svm.model <- svm(xMat$group[indx] ~ .,data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
svm.model <- svm(xMat$group[indx] ~ .,data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
svm.model <- svm(xMat$group[indx] ~ .,data=xMat[indx,], cost = 100, gamma = 1, probability=TRUE)
indx = which(is.na(oto$isAR))# Do American River classification
indx = which(is.na(oto$isAR))# Do American River classification
indx = which(is.na(oto$isAR))# Do American River classification
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")
library(adegenet)
library(hierfstat)
library(grDevices)
run = "allele10_125"
SNP = FALSE
if(run== "snp_125") SNP = TRUE
# Load in the .gen and .dat files -- same info
#genfile = paste(run,".gen",sep="")
detach(package:hierfstat)
datfile = paste(run,".dat",sep="")
A <- read.fstat(datfile)
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))
genotypes = g2h[,-1]
LOCI = dim(genotypes)[2]
N = 1000
library(pegas)
gt = genind2loci(A)
# We want to iterate over (1) sample size, (2) loci, (3) weights
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))
y = 0
lowery = 0
uppery = 0
for(ii in 1:36) {
mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture
nSampled = scenarios$samples[ii]
sampledLoci = scenarios$nloci[ii]
load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))
coefs = 0
for(j in 1:1000) {
coefs[j] = output[[j]][1,7]
}
y[ii] = mean(coefs,na.rm=T)
lowery[ii] = quantile(coefs,0.1,na.rm=T)
uppery[ii] = quantile(coefs,0.9,na.rm=T)
}
spacing = 0.04
col3 = "black"
col2 = "grey50"
col1 = "grey80"
plot(log(c(10,20,50,100,200,400))-3*spacing, y[1:6], col=col1, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery),na.rm=T), xlim=c(log(9),log(450)))
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))
axis(2)
box()
points(log(c(10,20,50,100,200,400))-spacing, y[7:12],col=col2,lwd=3,cex=1.3)
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)
mtext(expression(paste("Correlation between ",hat(F)[ST[1]],"*",hat(F)[ST[2]]," and ",r^2,sep="")),side=2,outer=T,padj=1.3)
# draw lines for 0.25 - 0.75 quantiles
for(i in 1:6) {
lines(rep(log(c(10,20,50,100,200,400))[i],2)-3*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)
}
for(i in 7:12) {
lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)
}
for(i in 13:18) {
lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)
}
