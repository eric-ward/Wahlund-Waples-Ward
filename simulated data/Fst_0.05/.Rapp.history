dim(dat)
names(dat)
dat$Database
names(dat)
dat$Class
table(dat$Class)
dir()
getwd()
which(dat$Class%in%c("Actinopterygii","Cephalaspidomorphi","Chondrichthyes","Osteichthyes"))
dat = dat[which(dat$Class%in%c("Actinopterygii","Cephalaspidomorphi","Chondrichthyes","Osteichthyes")),]
dim(dat)
dat
names(dat)
dat$ID
names(dat)
dat$ID
table(dat$ID)
write.csv(dat, "masterDat 052015.csv")
dir()
names(dat)
dim(dat)
# Load in the data. This dataset only contains the #
dat = read.csv("masterDat 052015.csv",header=T)
dat = read.csv("masterDat 052015.csv",header=T) #
NAHEAD = 5 # number of points ahead to forecast#
MODELS = 100 #
# dimension predicted and predictedSE to have the same dimensions#
# as dat, so that each observation will have a predicted value and se#
predicted = matrix(NA,dim(dat)[1],MODELS) #
predictedSE = matrix(NA,dim(dat)[1],MODELS)#
numRec = max(dat$ID) # number of unique time series #
model.output = array(list(),c(numRec,MODELS)) # list of model objects
numRec
?nnetTs
getwd()
names(dat)
dat$Species
trophic
clotting <- data.frame(#
u = c(5,10,15,20,30,40,60,80,100),#
lot1 = c(118,58,42,35,27,25,21,19,18),#
lot2 = c(69,35,26,21,18,16,13,12,12))#
glmfit1 <- glm(lot1 ~ log(u), data = clotting, family = Gamma(link = "log"))#
glmfit2 <- glm(lot2 ~ log(u), data = clotting, family = Gamma(link = "log"))
model <- SSModel(cbind(lot1, lot2) ~ log(u),#
u = 1/c(summary(glmfit1)$dispersion, summary(glmfit2)$dispersion),#
data = clotting, distribution = "gamma")
library(KFAS)
model <- SSModel(cbind(lot1, lot2) ~ log(u),#
u = 1/c(summary(glmfit1)$dispersion, summary(glmfit2)$dispersion),#
data = clotting, distribution = "gamma")
model
summary(model)
model
model$H
model
clotting
clotting
1/c(summary(glmfit1)$dispersion
1/c(summary(glmfit1)$dispersion
1/c(summary(glmfit1)$dispersion, summary(glmfit2)$dispersion)
1/c(summary(glmfit1)$dispersion, summary(glmfit2)$dispersion)
model <- SSModel(cbind(lot1) ~ log(u), u = 1/c(summary(glmfit1)$dispersion, data = clotting, distribution = "gamma")
model <- SSModel(cbind(lot1) ~ log(u), u = 1/c(summary(glmfit1)$dispersion, data = clotting, distribution = "gamma"))
model <- SSModel(cbind(lot1) ~ log(u), u = 1/c(summary(glmfit1)$dispersion, data = clotting, distribution = "gamma"))
model <- SSModel(cbind(lot1) ~ log(u), u = 1/c(summary(glmfit1)$dispersion, data = clotting, distribution = "gamma"))
model <- SSModel((lot1) ~ log(u), u = 1/c(summary(glmfit1)$dispersion, data = clotting, distribution = "gamma"))
model <- SSModel((lot1) ~ log(u), u = 1/c(summary(glmfit1)$dispersion, data = clotting, distribution = "gamma"))
u = c(5,10,15,20,30,40,60,80,100),#
lot1 = c(118,58,42,35,27,25,21,19,18),#
lot2 = c(69,35,26,21,18,16,13,12,12))
u = c(5,10,15,20,30,40,60,80,100),#
lot1 = c(118,58,42,35,27,25,21,19,18),#
lot2 = c(69,35,26,21,18,16,13,12,12))
u = c(5,10,15,20,30,40,60,80,100),#
lot1 = c(118,58,42,35,27,25,21,19,18),#
lot2 = c(69,35,26,21,18,16,13,12,12))
u = c(5,10,15,20,30,40,60,80,100),#
lot1 = c(118,58,42,35,27,25,21,19,18),#
lot2 = c(69,35,26,21,18,16,13,12,12))
u = c(5,10,15,20,30,40,60,80,100),#
lot1 = c(118,58,42,35,27,25,21,19,18),#
lot2 = c(69,35,26,21,18,16,13,12,12))
clotting <- data.frame(#
u = c(5,10,15,20,30,40,60,80,100),#
lot1 = c(118,58,42,35,27,25,21,19,18),#
lot2 = c(69,35,26,21,18,16,13,12,12))
clotting
model <- SSModel(lot1 ~ log(u), u = 1/c(summary(glmfit1)$dispersion, data = clotting, distribution = "gamma")
model <- SSModel(lot1 ~ log(u), u = 1/c(summary(glmfit1)$dispersion, data = clotting, distribution = "gamma"))
model <- SSModel(lot1 ~ log(u), u = 1/summary(glmfit1)$dispersion, data = clotting, distribution = "gamma")
model
model$H
?SSModel
model$Q
model <- SSModel(lot1 ~ log(u), u = 1/summary(glmfit1)$dispersion, data = clotting, distribution = "gamma")
model
names(model)
model$y
model$Z
model$H
model$T
names(model)
?
SSModel
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")#
library(adegenet)#
library(hierfstat)
run = "allele10_125"#
SNP = FALSE#
if(run== "snp_200") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}
y
lowery
spacing = 0.04#
col3 = "black"#
col2 = "grey50"#
col1 = "grey80"#
plot(log(c(10,20,50,100,200,400))-2*spacing, y[1:6], col=col1, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y[7:12],col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)
mtext(expression(paste("Correlation between ",hat(F)[IS]," and ",hat(F)[ST],sep="")), side = 2, outer=T,padj=1.5)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
	lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)#
}#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2), c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
for(i in 13:18) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("10% mixing","30% mixing","50% mixing"),col=c(col1,col2,col3),#
lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(b) 10 msat loci",cex=1.2)
spacing = 0.04#
col3 = "black"#
col2 = "grey50"#
col1 = "grey70"#
plot(log(c(10,20,50,100,200,400))-2*spacing, y[1:6], col=col1, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y[7:12],col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)#
#
mtext(expression(paste("Correlation between ",hat(F)[IS]," and ",hat(F)[ST],sep="")), side = 2, outer=T,padj=1.5)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
	lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)#
}#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2), c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
for(i in 13:18) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("10% mixing","30% mixing","50% mixing"),col=c(col1,col2,col3),#
lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(b) 10 msat loci",cex=1.2)
spacing = 0.04#
col3 = "black"#
col2 = "grey30"#
col1 = "grey70"#
plot(log(c(10,20,50,100,200,400))-2*spacing, y[1:6], col=col1, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y[7:12],col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)#
#
mtext(expression(paste("Correlation between ",hat(F)[IS]," and ",hat(F)[ST],sep="")), side = 2, outer=T,padj=1.5)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
	lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)#
}#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2), c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
for(i in 13:18) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("10% mixing","30% mixing","50% mixing"),col=c(col1,col2,col3),#
lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(b) 10 msat loci",cex=1.2)
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-2*spacing, y[1:6], col=col1, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y[7:12],col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)#
#
mtext(expression(paste("Correlation between ",hat(F)[IS]," and ",hat(F)[ST],sep="")), side = 2, outer=T,padj=1.5)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
	lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)#
}#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2), c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
for(i in 13:18) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("10% mixing","30% mixing","50% mixing"),col=c(col1,col2,col3),#
lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(b) 10 msat loci",cex=1.2)
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")#
library(adegenet)#
library(hierfstat)#
pdf("/users/eric.ward/dropbox/Fst_Fit_correlation project/Figure 01b.pdf")#
#run = "microsat_n1000_loci200_states20"#
#run = "snp_n1000_loci1000_states2"#
#run = "microsat_n1000_loci200_states10"#
run = "snp_140"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
par(mfrow=c(2,1),mgp=c(2,1,0),mai=c(0.7,0.7,0.1,0.1))#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-spacing, y[7:12], col=col2, xlab = "Individuals sampled", ylab = expression(paste("Correlation between ",F[IS]," and ",F[ST],sep="")),main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))+spacing, y[25:30],col=col3,lwd=3,cex=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 25:30) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-24],2)+spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("30% mixing (100 loci)","30% mixing (200 loci)"),col=c(col2,col3),#
lwd=c(3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21))#
legend('topleft',bty='n',"(a)",cex=1.2)#
#
#alleles with 10 states#
run = "allele10_125"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	cors = 0#
	for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
plot(log(c(10,20,50,100,200,400))-spacing, y[7:12], col=col2, xlab = "Individuals sampled", ylab = expression(paste("Correlation between ",F[IS]," and ",F[ST],sep="")),main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))+spacing, y[25:30],col=col3,lwd=3,cex=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 25:30) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-24],2)+spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("30% mixing (10 loci)","30% mixing (20 loci)"),col=c(col2,col3),#
lwd=c(3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21))#
legend('topleft',bty='n',"(b)",cex=1.2)#
#
dev.off()
#run = "microsat_n1000_loci200_states20"#
#run = "snp_n1000_loci1000_states2"#
#run = "microsat_n1000_loci200_states10"#
run = "snp_140"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
par(mfrow=c(2,1),mgp=c(2,1,0),mai=c(0.7,0.7,0.1,0.1))#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-spacing, y[7:12], col=col2, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))+spacing, y[25:30],col=col3,lwd=3,cex=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 25:30) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-24],2)+spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("30% mixing (100 loci)","30% mixing (200 loci)"),col=c(col2,col3),#
lwd=c(3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21))#
legend('topleft',bty='n',"(a)",cex=1.2)#
#
#alleles with 10 states#
run = "allele10_125"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	cors = 0#
	for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
plot(log(c(10,20,50,100,200,400))-spacing, y[7:12], col=col2, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))+spacing, y[25:30],col=col3,lwd=3,cex=1.3)#
#
mtext(expression(paste("Correlation between ",hat(F)[IS]," and ",hat(F)[ST],sep="")), side = 2, outer=T,padj=1.5)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 25:30) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-24],2)+spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("30% mixing (10 loci)","30% mixing (20 loci)"),col=c(col2,col3),#
lwd=c(3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21))#
legend('topleft',bty='n',"(b)",cex=1.2)
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")#
library(adegenet)#
library(hierfstat)#
pdf("/users/eric.ward/dropbox/Fst_Fit_correlation project/Figure 01b.pdf")#
#run = "microsat_n1000_loci200_states20"#
#run = "snp_n1000_loci1000_states2"#
#run = "microsat_n1000_loci200_states10"#
run = "snp_140"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
par(mfrow=c(2,1),mgp=c(2,1,0),mai=c(0.7,0.7,0.1,0.1))#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-spacing, y[7:12], col=col2, xlab = "", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))+spacing, y[25:30],col=col3,lwd=3,cex=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 25:30) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-24],2)+spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("30% mixing (100 loci)","30% mixing (200 loci)"),col=c(col2,col3),#
lwd=c(3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21))#
legend('topleft',bty='n',"(a)",cex=1.2)#
#
#alleles with 10 states#
run = "allele10_125"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	cors = 0#
	for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
plot(log(c(10,20,50,100,200,400))-spacing, y[7:12], col=col2, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))+spacing, y[25:30],col=col3,lwd=3,cex=1.3)#
#
mtext(expression(paste("Correlation between ",hat(F)[IS]," and ",hat(F)[ST],sep="")), side = 2, outer=T,padj=1.5)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 25:30) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-24],2)+spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("30% mixing (10 loci)","30% mixing (20 loci)"),col=c(col2,col3),#
lwd=c(3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21))#
legend('topleft',bty='n',"(b)",cex=1.2)#
#
dev.off()
m = matrix(runif(9),3,3)
m
solve(m)
m = matrix(rep(1,9),3,3)
m
diag(m) = 0.03
solve(m)
diag(m) = 0.003
solve(m)
diag(m) = 0.00003
solve(m)
diag(m) = 0.00003
load("/Users/eric.ward/Documents/Publications/2015 Brad sat tag acoustic recorder/k25_10minute_withDetections.Rdata")
ls()
library(R2jags)
jags.model
jags.model.informative
jags.model.uninformative
ls()
model
k25
names(k25)
jags.model
load("/Users/eric.ward/Documents/Publications/2015 Brad sat tag acoustic recorder/k25_10minute.Rdata")
rm(list=ls())
load("/Users/eric.ward/Documents/Publications/2015 Brad sat tag acoustic recorder/k25_10minute.Rdata")
ls()
singleStateFit
names(singleStateFit)
names(singleStateFit$25)
names(singleStateFit$25)
names(singleStateFit$'25)
names(singleStateFit)
names(singleStateFit)
names(singleStateFit$"25")
names(singleStateFit$"25"$mcmc)
names(singleStateFit$"25"$mcmc$x)
dim(singleStateFit$"25"$mcmc$x)
summary(singleStateFit$"25"$mcmc$x[,1,,])
summary(singleStateFit$"25"$mcmc$x[,2,,])
quantile(singleStateFit$"25"$mcmc$x[,2,,],c(0.025,0.5,0.1))
quantile(singleStateFit$"25"$mcmc$x[,2,,],c(0.025,0.05,0.1))
hist(singleStateFit$"25"$mcmc$x[,2,,],100)
hist(singleStateFit$"25"$mcmc$x[,2,,],100,col="grey70")
lines(rep(quantile(singleStateFit$"25"$mcmc$x[,2,,],c(0.025)),2),c(0,1.0e10),col="red")
lines(rep(quantile(singleStateFit$"25"$mcmc$x[,2,,],c(0.05)),2),c(0,1.0e10),col="red")
lines(rep(quantile(singleStateFit$"25"$mcmc$x[,2,,],c(0.1)),2),c(0,1.0e10),col="red")
hist(singleStateFit$"25"$mcmc$x[,2,,],100,col="grey70",xlab="Latitude",main="K25 Satellite track")
lines(rep(quantile(singleStateFit$"25"$mcmc$x[,2,,],c(0.025)),2),c(0,1.0e10),col="red")
lines(rep(quantile(singleStateFit$"25"$mcmc$x[,2,,],c(0.05)),2),c(0,1.0e10),col="red")
lines(rep(quantile(singleStateFit$"25"$mcmc$x[,2,,],c(0.1)),2),c(0,1.0e10),col="red")
getwd()
setwd("/users/eric.ward/downloads")
dir()
a2013 = read.csv("Adult_2013.csv")
a2015 = read.csv("Adult_2015.csv")
a2015 = read.csv("Adult_2015.csv",header=T)
a2015 = read.table("Adult_2015.csv",sep=",")
a2015 = read.table("Adult_2015.csv",sep=",")
a2013 = read.csv("Adult_2013.csv",header=T)#
a2014 = read.csv("Adult_2014.csv",header=T)#
a2015 = read.csv("Adult_2015.csv",header=T)
a2013
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",lines=c(0,10000))#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)))#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)))#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"))
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)))#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)))#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Chinook")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Chinook", main="BON")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')
names(a2013)
par(mfrow = c(2,1),mgp =c(2,1,0),mai=c(0.5,0.5,0.1,0.1))#
#
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Chinook", main="BON",xlab="Day")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')#
#
ys = c(a2013$Steelhead[1:120], a2014$Steelhead[1:120], a2015$Steelhead[1:120])#
plot(a2013$Steelhead[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Steelhead", main="BON",xlab="Day")#
lines(a2014$Steelhead[1:120], lwd = 3, col="tomato1")#
lines(a2015$Steelhead[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')
par(mfrow = c(2,1),mgp =c(2,1,0),mai=c(0.5,0.7,0.1,0.1))#
#
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Chinook", main="BON",xlab="Day")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')#
#
ys = c(a2013$Steelhead[1:120], a2014$Steelhead[1:120], a2015$Steelhead[1:120])#
plot(a2013$Steelhead[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Steelhead", main="BON",xlab="Day")#
lines(a2014$Steelhead[1:120], lwd = 3, col="tomato1")#
lines(a2015$Steelhead[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')
par(mfrow = c(2,1),mgp =c(2,1,0),mai=c(0.5,0.7,0.15,0.1))#
#
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Chinook", main="BON",xlab="Day")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')#
#
ys = c(a2013$Steelhead[1:120], a2014$Steelhead[1:120], a2015$Steelhead[1:120])#
plot(a2013$Steelhead[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Steelhead", main="BON",xlab="Day")#
lines(a2014$Steelhead[1:120], lwd = 3, col="tomato1")#
lines(a2015$Steelhead[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')
par(mfrow = c(2,1),mgp =c(2,1,0),mai=c(0.5,0.7,0.2,0.1))#
#
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Chinook", main="BON",xlab="Day")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')#
#
ys = c(a2013$Steelhead[1:120], a2014$Steelhead[1:120], a2015$Steelhead[1:120])#
plot(a2013$Steelhead[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Steelhead", main="BON",xlab="Day")#
lines(a2014$Steelhead[1:120], lwd = 3, col="tomato1")#
lines(a2015$Steelhead[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')
par(mfrow = c(2,1),mgp =c(2,1,0),mai=c(0.7,0.7,0.2,0.1))#
#
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Chinook", main="BON",xlab="Day")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')#
#
ys = c(a2013$Steelhead[1:120], a2014$Steelhead[1:120], a2015$Steelhead[1:120])#
plot(a2013$Steelhead[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Steelhead", main="BON",xlab="Day")#
lines(a2014$Steelhead[1:120], lwd = 3, col="tomato1")#
lines(a2015$Steelhead[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')
pdf("Runs 2013_2015.pdf")#
par(mfrow = c(2,1),mgp =c(2,1,0),mai=c(0.7,0.7,0.2,0.1))#
#
ys = c(a2013$ChinookAdult[1:120], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Chinook", main="BON",xlab="Day")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')#
#
ys = c(a2013$Steelhead[1:120], a2014$Steelhead[1:120], a2015$Steelhead[1:120])#
plot(a2013$Steelhead[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Steelhead", main="BON",xlab="Day")#
lines(a2014$Steelhead[1:120], lwd = 3, col="tomato1")#
lines(a2015$Steelhead[1:120], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')#
dev.off()
y1 = log(a2013$ChinookAdult[1:120])#
y2 = log(a2014$ChinookAdult[1:120])#
y3 = log(a2015$ChinookAdult[1:120])
y1
y1 = log(a2013$ChinookAdult[1:120]+1)#
y2 = log(a2014$ChinookAdult[1:120]+1)#
y3 = log(a2015$ChinookAdult[1:120]+1)#
plot(a2013$ChinookAdult[1:120], lwd = 3, col="grey70",type="l",ylim=c(0,max(c(y1,y2,y3))), ylab="Chinook", main="BON",xlab="Day")#
lines(a2014$ChinookAdult[1:120], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:120], lwd = 3, col="cadetblue")
y1 = log(a2013$ChinookAdult[1:120]+1)#
y2 = log(a2014$ChinookAdult[1:120]+1)#
y3 = log(a2015$ChinookAdult[1:120]+1)#
plot(y1, lwd = 3, col="grey70",type="l",ylim=c(0,max(c(y1,y2,y3))), ylab="Chinook", main="BON",xlab="Day")#
lines(y2, lwd = 3, col="tomato1")#
lines(y3, lwd = 3, col="cadetblue")
y1 = log(a2013$ChinookAdult[1:120]+1)#
y2 = log(a2014$ChinookAdult[1:120]+1)#
y3 = log(a2015$ChinookAdult[1:120]+1)#
plot(y1, lwd = 3, col="grey70",type="l",ylim=c(0,max(c(y1,y2,y3))), ylab="Chinook", main="BON",xlab="Day")#
lines(y2, lwd = 3, col="tomato1")#
lines(y3, lwd = 3, col="cadetblue")#
#
y1 = log(a2013$Steelhead[1:120]+1)#
y2 = log(a2014$Steelhead[1:120]+1)#
y3 = log(a2015$Steelhead[1:120]+1)#
lines(y1, lty=2,lwd = 3, col="grey70")#
lines(y2, lty=2,lwd = 3, col="tomato1")#
lines(y3, lty=2,lwd = 3, col="cadetblue")
y1 = log(a2013$ChinookAdult[1:120]+1)#
y2 = log(a2014$ChinookAdult[1:120]+1)#
y3 = log(a2015$ChinookAdult[1:120]+1)#
plot(y1, lwd = 2, col="grey70",type="l",ylim=c(0,max(c(y1,y2,y3))), ylab="Chinook", main="BON",xlab="Day")#
lines(y2, lwd = 2, col="tomato1")#
lines(y3, lwd = 2, col="cadetblue")#
#
y1 = log(a2013$Steelhead[1:120]+1)#
y2 = log(a2014$Steelhead[1:120]+1)#
y3 = log(a2015$Steelhead[1:120]+1)#
lines(y1, lty=2,lwd = 2, col="grey70")#
lines(y2, lty=2,lwd = 2, col="tomato1")#
lines(y3, lty=2,lwd = 2, col="cadetblue")
y1 = log(a2013$ChinookAdult[1:120]+1)#
y2 = log(a2014$ChinookAdult[1:120]+1)#
y3 = log(a2015$ChinookAdult[1:120]+1)#
plot(y1, lwd = 2, col="grey70",type="l",ylim=c(0,max(c(y1,y2,y3))), ylab="Chinook", main="BON",xlab="Day")#
lines(y2, lwd = 2, col="tomato1")#
lines(y3, lwd = 2, col="cadetblue")#
#
y1 = log(a2013$Steelhead[1:120]+1)#
y2 = log(a2014$Steelhead[1:120]+1)#
y3 = log(a2015$Steelhead[1:120]+1)#
lines(y1, lty=2,lwd = 2, col="grey70")#
lines(y2, lty=2,lwd = 2, col="tomato1")#
lines(y3, lty=2,lwd = 2, col="cadetblue")#
#
legend('topleft',c("2013 Chinook","2014 Chinook","2015 Chinook","2013 Steelhead","2014 Steelhead","2015 Steelhead"),lwd=2,col=c("grey70","tomato1","cadetblue","grey70","tomato1","cadetblue"),lty=c(1,1,1,2,2,2),bty='n')
pdf("Runs 2013_2015_logspace.pdf")#
y1 = log(a2013$ChinookAdult[1:120]+1)#
y2 = log(a2014$ChinookAdult[1:120]+1)#
y3 = log(a2015$ChinookAdult[1:120]+1)#
plot(y1, lwd = 2, col="grey70",type="l",ylim=c(0,max(c(y1,y2,y3))), ylab="Fish returning", main="BON",xlab="Day")#
lines(y2, lwd = 2, col="tomato1")#
lines(y3, lwd = 2, col="cadetblue")#
#
y1 = log(a2013$Steelhead[1:120]+1)#
y2 = log(a2014$Steelhead[1:120]+1)#
y3 = log(a2015$Steelhead[1:120]+1)#
lines(y1, lty=2,lwd = 2, col="grey70")#
lines(y2, lty=2,lwd = 2, col="tomato1")#
lines(y3, lty=2,lwd = 2, col="cadetblue")#
#
legend('topleft',c("2013 Chinook","2014 Chinook","2015 Chinook","2013 Steelhead","2014 Steelhead","2015 Steelhead"),lwd=2,col=c("grey70","tomato1","cadetblue","grey70","tomato1","cadetblue"),lty=c(1,1,1,2,2,2),bty='n')#
dev.off()
par(mfrow = c(2,1),mgp =c(2,1,0),mai=c(0.7,0.7,0.2,0.1))#
#
ys = c(a2013$ChinookAdult[1:150], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:150], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Chinook", main="BON",xlab="Day")#
lines(a2014$ChinookAdult[1:150], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:150], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')#
#
ys = c(a2013$Steelhead[1:150], a2014$Steelhead[1:120], a2015$Steelhead[1:120])#
plot(a2013$Steelhead[1:150], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Steelhead", main="BON",xlab="Day")#
lines(a2014$Steelhead[1:150], lwd = 3, col="tomato1")#
lines(a2015$Steelhead[1:150], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')
pdf("Runs 2013_2015.pdf")#
par(mfrow = c(2,1),mgp =c(2,1,0),mai=c(0.7,0.7,0.2,0.1))#
#
ys = c(a2013$ChinookAdult[1:150], a2014$ChinookAdult[1:120], a2015$ChinookAdult[1:120])#
plot(a2013$ChinookAdult[1:150], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Chinook", main="BON",xlab="Day")#
lines(a2014$ChinookAdult[1:150], lwd = 3, col="tomato1")#
lines(a2015$ChinookAdult[1:150], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')#
#
ys = c(a2013$Steelhead[1:150], a2014$Steelhead[1:120], a2015$Steelhead[1:120])#
plot(a2013$Steelhead[1:150], lwd = 3, col="grey70",type="l",ylim=c(0,max(ys)), ylab="Steelhead", main="BON",xlab="Day")#
lines(a2014$Steelhead[1:150], lwd = 3, col="tomato1")#
lines(a2015$Steelhead[1:150], lwd = 3, col="cadetblue")#
legend('topleft',c("2013","2014","2015"),lwd=3,col=c("grey70","tomato1","cadetblue"),bty='n')#
dev.off()
getwd()
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")#
library(adegenet)#
library(hierfstat)#
pdf("/users/eric.ward/dropbox/Fst_Fit_correlation project/Figure 01 Fis v Fst_mixing.pdf")#
#run = "microsat_n1000_loci200_states20"#
#run = "snp_n1000_loci1000_states2"#
#run = "microsat_n1000_loci200_states10"#
run = "snp_140"#
SNP = FALSE#
if(run== "snp_140") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
    #cors = unlist(lapply(output,cor,use="pairwise.complete"))[seq(2,4000,4)]#
    cors = 0#
    for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
    y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
par(mfrow=c(2,1),mgp=c(2,1,0),mai=c(0.7,0.7,0.1,0.1))#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-2*spacing, y[1:6], col=col1, xlab = "", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y[7:12],col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
	lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)#
}#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2), c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
for(i in 13:18) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("10% mixing","30% mixing","50% mixing"),col=c(col1,col2,col3),#
lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(a) 100 SNPs",cex=1.2)#
#
#alleles with 10 states#
run = "allele10_125"#
SNP = FALSE#
if(run== "snp_200") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-2*spacing, y[1:6], col=col1, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y[7:12],col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)#
#
mtext(expression(paste("Correlation between ",hat(F)[IS]," and ",hat(F)[ST],sep="")), side = 2, outer=T,padj=1.5)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
	lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)#
}#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2), c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
for(i in 13:18) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("10% mixing","30% mixing","50% mixing"),col=c(col1,col2,col3),#
lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(b) 10 msat loci",cex=1.2)#
#
dev.off()
#############################################################################################################
# Figure 1b. Plot showing effects of increasing sampling #
# Y is correlation between Fis / Fst#
# Make stacked plot with SNP on top, and 10-allele state on the bottom#
#############################################################################################################
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")#
library(adegenet)#
library(hierfstat)#
pdf("/users/eric.ward/dropbox/Fst_Fit_correlation project/Figure 01b.pdf")#
#run = "microsat_n1000_loci200_states20"#
#run = "snp_n1000_loci1000_states2"#
#run = "microsat_n1000_loci200_states10"#
run = "snp_140"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
par(mfrow=c(2,1),mgp=c(2,1,0),mai=c(0.7,0.7,0.1,0.1))#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-spacing, y[7:12], col=col2, xlab = "", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))+spacing, y[25:30],col=col3,lwd=3,cex=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 25:30) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-24],2)+spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("30% mixing (100 loci)","30% mixing (200 loci)"),col=c(col2,col3),#
lwd=c(3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21))#
legend('topleft',bty='n',"(a)",cex=1.2)#
#
#alleles with 10 states#
run = "allele10_125"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	cors = 0#
	for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
plot(log(c(10,20,50,100,200,400))-spacing, y[7:12], col=col2, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))+spacing, y[25:30],col=col3,lwd=3,cex=1.3)#
#
mtext(expression(paste("Correlation between ",hat(F)[IS]," and ",hat(F)[ST],sep="")), side = 2, outer=T,padj=1.5)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 25:30) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-24],2)+spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("30% mixing (10 loci)","30% mixing (20 loci)"),col=c(col2,col3),#
lwd=c(3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21))#
legend('topleft',bty='n',"(b)",cex=1.2)#
#
dev.off()
#############################################################################################################
# Figure 2. Plot showing effects of increasing Fst  #
# Y is correlation between Fis / Fst#
# Make stacked plot with SNP on top, and 10-allele state on the bottom#
#############################################################################################################
#
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.025")#
library(adegenet)#
library(hierfstat)#
#
run = "snp_50"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:6) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
y1 = y#
lowery1=lowery#
uppery1=uppery#
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")#
library(adegenet)#
library(hierfstat)#
#
run = "snp_140"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:6) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
y2 = y#
lowery2=lowery#
uppery2=uppery#
#
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.1")#
library(adegenet)#
library(hierfstat)#
#
run = "snp_300"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:6) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	cors = 0#
	for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
y3 = y#
lowery3=lowery#
uppery3=uppery#
#
######################calculate allele 10#
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.025")#
library(adegenet)#
library(hierfstat)#
#
run = "allele10_55"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:6) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
y4 = y#
lowery4=lowery#
uppery4=uppery#
#
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")#
library(adegenet)#
library(hierfstat)#
#
run = "allele10_125"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:6) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
y5 = y#
lowery5=lowery#
uppery5=uppery#
#
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.1")#
library(adegenet)#
library(hierfstat)#
#
run = "allele10_375"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:6) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
y6 = y#
lowery6=lowery#
uppery6=uppery#
pdf("/users/eric.ward/dropbox/Fst_Fit_correlation project/Figure 02 Fis v Fst_trueFst.pdf")#
par(mfrow = c(2,1),mgp=c(2,1,0),mai=c(0.7,0.7,0.1,0.1))#
minY = min(c(lowery1,lowery2,lowery3))#
maxY = max(c(uppery1,uppery2,uppery3))#
plot(log(c(10,20,50,100,200,400))-2*spacing, y1, col=col1, xlab = "", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=c(minY,maxY), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y2,col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y3,col=col3,lwd=3,cex=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
	lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery1[i],uppery1[i]), col = col1,lwd=2,lty=1)#
	lines(rep(log(c(10,20,50,100,200,400))[i],2), c(lowery2[i],uppery2[i]), col = col2,lwd=2,lty=1)#
	lines(rep(log(c(10,20,50,100,200,400))[i],2)+2*spacing, c(lowery3[i],uppery3[i]), col = col3,lwd=2,lty=1)#
}#
#
legend('bottomright',c(expression(paste(F[ST]," = 0.025",sep="")),expression(paste(F[ST]," = 0.05",sep="")),expression(paste(F[ST]," = 0.1",sep=""))),col=c(col1,col2,col3),#
lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(a) 100 SNPs",cex=1.2)#
#
minY = min(c(lowery4,lowery5,lowery6))#
maxY = max(c(uppery4,uppery5,uppery6))#
plot(log(c(10,20,50,100,200,400))-2*spacing, y4, col=col1, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=c(minY,maxY), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y5,col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y6,col=col3,lwd=3,cex=1.3)#
#
mtext(expression(paste("Correlation between ",hat(F)[IS]," and ",hat(F)[ST],sep="")),side=2,outer=T,padj=1.5)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
	lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery4[i],uppery4[i]), col = col1,lwd=2,lty=1)#
	lines(rep(log(c(10,20,50,100,200,400))[i],2), c(lowery5[i],uppery5[i]), col = col2,lwd=2,lty=1)#
	lines(rep(log(c(10,20,50,100,200,400))[i],2)+2*spacing, c(lowery6[i],uppery6[i]), col = col3,lwd=2,lty=1)#
}#
#
legend('bottomright',c(expression(paste(F[ST]," = 0.025",sep="")),expression(paste(F[ST]," = 0.05",sep="")),expression(paste(F[ST]," = 0.1",sep=""))),col=c(col1,col2,col3),#
lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(b) 10 msat loci",cex=1.2)#
#
dev.off()#
#############################################################################################################
# Figure 3. Estimate slope for Zhivotovsky paper  #
# Is relationship 1:1? #
#############################################################################################################
pdf("/users/eric.ward/dropbox/Fst_Fit_correlation project/Figure 03 Zhivitovsky slopes.pdf")#
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")#
library(adegenet)#
library(hierfstat)#
#
#run = "allele10state_200"#
run = "snp_140"#
SNP = FALSE#
if(run== "snp_140") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
#
for(ii in 1:36) {#
  mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
  nSampled = scenarios$samples[ii]#
  sampledLoci = scenarios$nloci[ii]#
  load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
  lhs = output[[1]][,3] - output[[1]][,6] # LHS of Zhivotovsky#
  rhs = output[[1]][,4] # RHS of Zhivotovsky  #
  coefs = 0#
  for(j in 1:1000) {#
    lhs = c(output[[j]][,3] - output[[j]][,6])#
    rhs = c(output[[j]][,4])  #
    indx = which(is.na(lhs+rhs)==FALSE & is.finite(lhs+rhs)==TRUE)#
    coefs[j] = as.numeric(try(coef(lm(log(lhs)~-1+log(rhs))), silent=TRUE))#
  }#
  y[ii] = mean(coefs,na.rm=T)#
  lowery[ii] = quantile(coefs,0.1,na.rm=T)#
  uppery[ii] = quantile(coefs,0.9,na.rm=T)#
}#
#
par(mfrow=c(2,1),mgp=c(2,1,0),mai=c(0.7,0.7,0.1,0.1))#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-2*spacing, y[1:6], col=col1, xlab = "", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery,1.05),na.rm=T), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y[7:12],col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
  lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)#
}#
for(i in 7:12) {#
  lines(rep(log(c(10,20,50,100,200,400))[i-6],2), c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
for(i in 13:18) {#
  lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("10% mixing","30% mixing","50% mixing"),col=c(col1,col2,col3),#
       lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(a) 100 SNPs",cex=1.2)#
run = "allele10_125"#
SNP = FALSE#
if(run== "snp_200") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
#
for(ii in 1:36) {#
  mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
  nSampled = scenarios$samples[ii]#
  sampledLoci = scenarios$nloci[ii]#
  load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
  lhs = output[[1]][,3] - output[[1]][,6] # LHS of Zhivotovsky#
  rhs = output[[1]][,4] # RHS of Zhivotovsky  #
  coefs = 0#
  for(j in 1:1000) {#
    lhs = c(output[[j]][,3] - output[[j]][,6])#
    rhs = c(output[[j]][,4])  #
    indx = which(is.na(lhs+rhs)==FALSE & is.finite(lhs+rhs)==TRUE)#
    coefs[j] = as.numeric(try(coef(lm(log(lhs)~-1+log(rhs))), silent=TRUE))#
  }#
  y[ii] = mean(coefs,na.rm=T)#
  lowery[ii] = quantile(coefs,0.1,na.rm=T)#
  uppery[ii] = quantile(coefs,0.9,na.rm=T)#
}#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-2*spacing, y[1:6], col=col1, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery,1.05),na.rm=T), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y[7:12],col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)#
#
mtext("Slope from Zhivitovsky", side=2,outer=T,padj=2)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
  lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)#
}#
for(i in 7:12) {#
  lines(rep(log(c(10,20,50,100,200,400))[i-6],2), c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
for(i in 13:18) {#
  lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("10% mixing","30% mixing","50% mixing"),col=c(col1,col2,col3),#
       lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(b) 10 msat loci",cex=1.2)#
#
dev.off()#
#############################################################################################################
# Figure 4. Estimate correlation between correlations#
#############################################################################################################
library(grDevices)#
pdf("/users/eric.ward/dropbox/Fst_Fit_correlation project/Figure 04 Correlation Fst1Fst2.pdf")#
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")#
library(adegenet)#
library(hierfstat)#
#
#run = "allele10state_200"#
run = "snp_140"#
SNP = FALSE#
if(run== "snp_140") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
#
for(ii in 1:36) {#
  mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
  nSampled = scenarios$samples[ii]#
  sampledLoci = scenarios$nloci[ii]#
  load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
  coefs = 0#
  for(j in 1:1000) {#
    coefs[j] = output[[j]][1,7]#
  }#
  y[ii] = mean(coefs,na.rm=T)#
  lowery[ii] = quantile(coefs,0.1,na.rm=T)#
  uppery[ii] = quantile(coefs,0.9,na.rm=T)#
}#
#
par(mfrow=c(2,1),mgp=c(2,1,0),mai=c(0.7,0.7,0.1,0.1))#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-2*spacing, y[1:6], col=col1, xlab = "", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery),na.rm=T), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))-0*spacing, y[7:12],col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
  lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)#
}#
for(i in 7:12) {#
  lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-0*spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
for(i in 13:18) {#
  lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("10% mixing","30% mixing","50% mixing"),col=c(col1,col2,col3),#
       lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(a) 100 SNPs",cex=1.2)#
#
run = "allele10_125"#
SNP = FALSE#
if(run== "snp_125") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
#
for(ii in 1:36) {#
  mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
  nSampled = scenarios$samples[ii]#
  sampledLoci = scenarios$nloci[ii]#
  load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
  coefs = 0#
  for(j in 1:1000) {#
    coefs[j] = output[[j]][1,7]#
  }#
  y[ii] = mean(coefs,na.rm=T)#
  lowery[ii] = quantile(coefs,0.1,na.rm=T)#
  uppery[ii] = quantile(coefs,0.9,na.rm=T)#
}#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-2*spacing, y[1:6], col=col1, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery),na.rm=T), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400)), y[7:12],col=col2,lwd=3,cex=1.3)#
points(log(c(10,20,50,100,200,400))+2*spacing, y[13:18],col=col3,lwd=3,cex=1.3)#
#
mtext(expression(paste("Correlation between ",hat(F)[ST[1]],"*",hat(F)[ST[2]]," and ",r^2,sep="")),side=2,outer=T,padj=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 1:6) {#
  lines(rep(log(c(10,20,50,100,200,400))[i],2)-2*spacing, c(lowery[i],uppery[i]),lwd=2,lty=1, col=col1)#
}#
for(i in 7:12) {#
  lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-0*spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
for(i in 13:18) {#
  lines(rep(log(c(10,20,50,100,200,400))[i-12],2)+2*spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("10% mixing","30% mixing","50% mixing"),col=c(col1,col2,col3),#
       lwd=c(3,3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21,21))#
legend('topleft',bty='n',"(b) 10 msat loci",cex=1.2)#
#
dev.off()
library(adegenet)#
library(genetics)#
#
FST = "0.05"#
#
setwd(paste("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_",FST,sep=""))
iii=3
if(iii==1) {#
	if(FST=="0.025") run = "allele10_55"#
	if(FST=="0.05") run = "allele10_125"#
	if(FST=="0.1") run = "allele10_375"#
}#
if(iii==2) {#
	if(FST=="0.025") run = "allele20_55"	#
	if(FST=="0.05") run = "allele20_125"	#
	if(FST=="0.1") run = "allele20_375"#
}#
if(iii==3) {#
	if(FST=="0.025") run = "snp_50"#
	if(FST=="0.05") run = "snp_140"	#
	if(FST=="0.1") run = "snp_300"#
}
SNP = FALSE#
if(substr(run,1,3) == "snp") SNP = TRUE#
library(hierfstat)#
# Load in the .gen and .dat files -- same info#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
#A <- import2genind(datfile)#
A <- read.fstat(datfile)#
#
N = length(A@ind.names) # number of animals from both pops#
g2h = genind2hierfstat(A,pop=c(rep(1,N/2), rep(2,N/2)))#
gen =genind2genotype(A) # create genotype object#
library(hierfstat)#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
STATES = c(10, 20, 2)[iii]#
#
library(pegas)#
gt = genind2loci(A)
# Score the genotypes so they can be used to calculate r^2#
# Calculate correlation over each allelic state. Average across states#
g1 = matrix(0,dim(gen)[1],dim(gen)[2])#
g2 = matrix(0,dim(gen)[1],dim(gen)[2])#
gMat = array(0,dim=c(dim(gen)[1],dim(gen)[2],STATES))#
for(i in 1:dim(gen)[1]) {#
  for(j in 1:dim(gen)[2]) {#
    g1[i,j] = as.numeric(strsplit(as.character(gen[i,j]),"/")[[1]][1])#
    g2[i,j] = as.numeric(strsplit(as.character(gen[i,j]),"/")[[1]][2]) #
    gMat[i,j,g1[i,j]] = gMat[i,j,g1[i,j]] + 1#
    gMat[i,j,g2[i,j]] = gMat[i,j,g2[i,j]] + 1#
  }#
}#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))
scenarios
iii=6
print(ii)#
mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
nSampled = scenarios$samples[ii] # total animals in the mixture#
sampledLoci = scenarios$nloci[ii] # number of loci to sample#
#
weights = c(mixPop1, 1-mixPop1) #
sampledAnimals = ceiling(nSampled * weights) # numbers of animals to sample from each population#
#
# draw samples from each population the same size as the mixture to calculate Fst#
# sample same number from pop 1/2, then create mixture based on those samples#
# m = 0.001 = 1/10 th of migrant per generation.N = 1000#
# Fst = 0.025, 0.05, 0.1#
# 2 sets of samples: 1 for Fst (size = S at each locus), 1 (total size S) for Fis/R2#
SIMS = 1000#
output = list()
for(i in 1:SIMS) {#
	print(i)#
   # Generate constant samples of same size from pop 1 and 2#
   # draw N/2 animals from each subpopulation#
   animals = sample(seq(1,N/2), size = nSampled, replace=F)#
   animals2 = sample(seq(N/2+1,N), size = nSampled, replace=F)    #
   # Generate random sample of loci from the populations -- same loci#
   loci = sample(seq(1,LOCI), size = sampledLoci, replace=F)#
#
   # calculate Fst following Nei & Chesser 1983#
   # Fst is calculated based on mixture of 2 pops. #
   subft = g2h[c(animals,animals2),c(1,loci+1)]#
   output[[i]] = matrix(NA, sampledLoci, 7)#
   rownames(output[[i]]) = names(subft)[-1]#
   colnames(output[[i]]) = c("Fst","Fis","Zh1","Zh2","delta","Zh3","CorFst1Fst2_R2")#
   #output[[i]][,1] = wc(subft)$per.loc$FST#
   output[[i]][,1] = basic.stats(subft)$perloc$Fst#
   Fstvec = basic.stats(subft)$perloc$Fst#
   #Fstvec = basic.stats(g2h)$perloc$Fst# Check Robin's calcs#
   Fst1_Fst2 = Fstvec%o%Fstvec # product of Fst1 and Fst2#
   #Ht = basic.stats(subft)$perloc$Ht # used below#
   #Hs = basic.stats(subft)$Hs # used below  #
#
   # Generate 2nd sample for Fis / R2#
   animals = sample(seq(1,N/2), size = sampledAnimals[1], replace=F)#
   animals2 = sample(seq(N/2+1,N), size = sampledAnimals[2], replace=F)  #
   # Divide those in half to create actual mixture#
   #animals = animals[1:(nSampled/2)]#
   #animals2 = animals2[1:(nSampled/2)]#
   subft = g2h[c(animals,animals2),c(1,loci+1)]#
   # Fst 1 and Fst 2 by locus#
   div1 = basic.stats(subft)$Hs[,1]#
   div2 = basic.stats(subft)$Hs[,2]#
   output[[i]][,5] = (div1 - div2)/(div1+div2) # gene diveristy#
   # Fis is calculated including all animals as same pop#
   subft$pop=1#
   rownames(subft) = paste(seq(1,nSampled))#
   #subft$pop[1]=1#
   output[[i]][,2] = basic.stats(subft)$perloc$Fis#
   output[[i]][,3] = log(1/output[[i]][,2] - 1) # ln(1/Fis -1)#
   output[[i]][,4] = log(1/output[[i]][,1] - 1) # ln(1/Fst -1)#
   output[[i]][,6] = log((1 - output[[i]][,5]*(1 - 2*scenarios$mix[ii]))/(4*scenarios$mix[ii]*(1-scenarios$mix[ii])))#
   # Calculate correlation over each allelic state. Average across states#
   # there are 10*9/2 = 45 pairs of loci and 45 Fst1*Fst2 values.  consider only the comparisons of locus1 and locus2#
   # there are 10x10 = 100 comparisons of alleles at locus 1 vs locus 2#
   # recode to 0,1,2 and calculate r^2 for each of the 100 comparisons#
   # mean of the 100 r^2 values is the mean r^2 for that pair of loci#
   # repeat for the other 44 comparisons of loci and compute the correlation of r^2 and Fst1*Fst2#
   subgMat = gMat[c(animals,animals2),loci,]#
   corMat = matrix(0, length(loci), length(loci))#
   for(iii in 1:length(loci)) {#
     for(jjj in 1:length(loci)) {#
       # pairwise comparaison of all ellelic correlatinos #
       corMat[iii,jjj] = mean(cor(cbind(subgMat[,iii,],subgMat[,jjj,]))[1:STATES,((STATES+1):(2*STATES))]^2, na.rm=T)#
     }    #
   }#
   output[[i]][,7]=cor(corMat[lower.tri(corMat)], Fst1_Fst2[lower.tri(Fst1_Fst2)], use = "pairwise.complete.obs")#
#
} # end i sims#
#
# save this output list to a file#
save(output,file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))
m = diag(runif(3))
m
solve(m)
1/m
setwd("/users/eric.ward/dropbox/Fst_Fit_correlation project/simulated data/migration/Fst_0.05")#
library(adegenet)#
library(hierfstat)#
pdf("/users/eric.ward/dropbox/Fst_Fit_correlation project/Figure 01b.pdf")#
#run = "microsat_n1000_loci200_states20"#
#run = "snp_n1000_loci1000_states2"#
#run = "microsat_n1000_loci200_states10"#
run = "snp_140"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
par(mfrow=c(2,1),mgp=c(2,1,0),mai=c(0.7,0.7,0.1,0.1))#
#
spacing = 0.04#
col3 = "black"#
col2 = "grey40"#
col1 = "grey60"#
plot(log(c(10,20,50,100,200,400))-spacing, y[7:12], col=col2, xlab = "", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))+spacing, y[25:30],col=col3,lwd=3,cex=1.3)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 25:30) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-24],2)+spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("30% mixing (100 loci)","30% mixing (200 loci)"),col=c(col2,col3),#
lwd=c(3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21))#
legend('topleft',bty='n',"(a)",cex=1.2)#
#
#alleles with 10 states#
run = "allele10_125"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	cors = 0#
	for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}#
#
plot(log(c(10,20,50,100,200,400))-spacing, y[7:12], col=col2, xlab = "Individuals sampled", ylab = "",main="",axes=F,cex=1.3,lwd=3,ylim=range(c(y,lowery,uppery)), xlim=c(log(9),log(450)))#
axis(1,at = log(c(10,20,50,100,200,400)),labels = c("10","20","50","100","200","400"))#
axis(2)#
box()#
points(log(c(10,20,50,100,200,400))+spacing, y[25:30],col=col3,lwd=3,cex=1.3)#
#
mtext(expression(paste("Correlation between ",hat(F)[IS]," and ",hat(F)[ST],sep="")), side = 2, outer=T,padj=1.5)#
#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 7:12) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-6],2)-spacing, c(lowery[i],uppery[i]), col = col2,lwd=2,lty=1)#
}#
# draw lines for 0.25 - 0.75 quantiles#
for(i in 25:30) {#
	lines(rep(log(c(10,20,50,100,200,400))[i-24],2)+spacing, c(lowery[i],uppery[i]), col = col3,lwd=2,lty=1)#
}#
legend('bottomright',c("30% mixing (10 loci)","30% mixing (20 loci)"),col=c(col2,col3),#
lwd=c(3,3),cex=0.9,bty='n',lty=NA,pch=c(21,21))#
legend('topleft',bty='n',"(b)",cex=1.2)#
#
dev.off()
#run = "microsat_n1000_loci200_states20"#
#run = "snp_n1000_loci1000_states2"#
#run = "microsat_n1000_loci200_states10"#
run = "snp_140"#
SNP = FALSE#
if(substr(run,1,3)== "snp") SNP = TRUE#
#
# Load in the .gen and .dat files -- same info#
#genfile = paste(run,".gen",sep="")#
detach(package:hierfstat)#
datfile = paste(run,".dat",sep="")#
A <- read.fstat(datfile)#
g2h = genind2hierfstat(A,pop=c(rep(1,500), rep(2,500)))#
#
genotypes = g2h[,-1]#
LOCI = dim(genotypes)[2]#
N = 1000#
#
library(pegas)#
gt = genind2loci(A)#
#
# We want to iterate over (1) sample size, (2) loci, (3) weights#
scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(10,20))#
if(SNP == TRUE) scenarios = expand.grid('samples' = c(10, 20,50,100,200,400), 'mix' = c(0.1,0.3,0.5),'nloci' = c(100,200))#
#
y = 0#
lowery = 0#
uppery = 0#
for(ii in 1:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}
ii
for(ii in 25:36) {#
	mixPop1 = scenarios$mix[ii]# Do weighted sampling of the two populations to create the mixture#
	nSampled = scenarios$samples[ii]#
	sampledLoci = scenarios$nloci[ii]#
    load(file = paste("output/",run,"_",paste("mix",mixPop1,sep=""),paste("_N",nSampled,sep=""),paste("_n",sampledLoci,sep=""),".Rdata",sep=""))#
    # calculate correlation between Fst and Fis, +/- SE#
	  cors = 0#
	  for(k in 1:1000) {cors[k] = cor(output[[k]][,1:2])[1,2]}#
	  y[ii] = median(cors,na.rm=T)#
    lowery[ii] = quantile(cors,0.1,na.rm=T)#
    uppery[ii] = quantile(cors,0.9,na.rm=T)#
}
y
scenarios[24]
scenarios[24,]
output
getwd()
mixPop1
nSampled
sampledLoci
output[[1]]
d = read.csv(file.choose())
names(d)
INSHORE = d[,3]#
EDGE = d[,4]#
INTERIOR = d[,5]#
#
YEAR = d[,1]#
SEASON = d[,2]#
GULF = d[,6]#
WINDDIR = d[,7]#
WINDMAG = d[,8]#
INLET = d[,9]
N = length(YEAR)#
D = diag(3)#
y = d[,3:5]
y
d[,3:5]
names(d)
L = lm(rep(1,N)~ as.factor(YEAR) + as.factor(SEASON) + as.factor(GULF) + as.factor(WINDDIR) + as.factor(WINDMAG) + as.factor(INLET))#
x = model.matrix(L)
x
dim(x)
d
dim(d)
model = cat("#
#
model {#
  # Factor / fixed effects for each covariate#
  for(i in 1:13) {B[i] ~ dnorm(0,0.01);}#
#
  # wishart prior on correlation matrix#
  covTau ~ dwish(D[1:3,1:3],3);#
  for(i in 1:3) {z[i] <-0;}#
  oneOverCV2 ~ dgamma(0.01,0.01);#
  CV <- 1/sqrt(oneOverCV2);#
  G_shp <- oneOverCV2;#
  Bregion[1] <- 0;#
  Bregion[2] ~ dnorm(0,0.01);#
  Bregion[3] ~ dnorm(0,0.01);  #
  for(i in 1:N) {#
  	e[i,1:3] ~ dmnorm(z[1:3],covTau);#
  	for(j in 1:3) {#
  		#pred[i,j] <- exp(min(inprod(B[1:13],x[i,1:13]),200));#
  		#nbp[i,j] <- oneOverCV2*(1/pred[i,j]);#
  		#nbr[i,j] <- pred[i,j]*nbp[i,j]/(1-nbp[i,j]);#
  		logit(pred[i,j]) <- e[i,j] + Bregion[j] + inprod(B[1:13],x[i,1:13]);#
#
  		y[i,j] ~ dnegbin(pred[i,j],G_shp);#
  	}#
  }#
}#
#
", file="model.txt")#
#
# These are all MCMC parameters...same as the ones we used#
mcmc.chainLength <- as.integer(20000)  # burn-in plus post-burn#
mcmc.burn <- as.integer(10000)#
mcmc.thin = 1#
mcmc.chains = 4      # needs to be at least 2 for DIC#
#
jags.data = list("x","D","N","y")#
jags.params=c("B", "pred","oneOverCV2","covTau","Bregion")#
model.loc = paste("model.txt",sep="")#
library(R2jags)
jags.model = jags(jags.data, inits = NULL, parameters.to.save= jags.params, model.file=model.loc, n.chains = mcmc.chains, n.burnin = mcmc.burn, n.thin = mcmc.thin, n.iter = mcmc.chainLength, DIC = TRUE) #
attach.jags(jags.model)
par(mfrow = c(2,2))#
hist(1/sqrt(oneOverCV2),40, col="grey70",main="CV",xlab="Coefficient")#
hist(B[,6],40, col="grey70",main="Gulf (2)",xlab="Coefficient")#
hist(B[,13],40, col="grey70",main="Inlet (2)",xlab="Coefficient")
par(mfrow = c(2,2))#
minx = min(c(B[,2],B[,3]))#
maxx = max(c(B[,2],B[,3]))#
hist(B[,2],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Year 2",xlab="Coefficient")#
hist(B[,3],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Year 3", xlim=range(c(B[,2],B[,3])),xlab="Coefficient")#
minx = min(c(B[,4],B[,5]))#
maxx = max(c(B[,4],B[,5]))#
hist(B[,4],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Season 2",xlab="Coefficient")#
hist(B[,5],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Season 3", xlim=range(c(B[,4],B[,5])),xlab="Coefficient")
par(mfrow = c(2,3))#
minx = min(c(B[,7],B[,8],B[,9]))#
maxx = max(c(B[,7],B[,8],B[,9]))#
hist(B[,7],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Winddir 2",xlab="Coefficient")#
hist(B[,8],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Winddir 3",xlab="Coefficient")#
hist(B[,9],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Winddir 4",xlab="Coefficient")#
minx = min(c(B[,10],B[,11],B[,12]))#
maxx = max(c(B[,10],B[,11],B[,12]))#
hist(B[,10],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Windmag 2",xlab="Coefficient")#
hist(B[,11],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Windmag 3",xlab="Coefficient")#
hist(B[,12],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Windmag 4",xlab="Coefficient")
par(mfrow = c(2,1))#
minx = min(c(Bregion[,2],Bregion[,3]))#
maxx = max(c(Bregion[,2],Bregion[,3]))#
hist(Bregion[,2],breaks = seq(minx,maxx,length.out=40), col="grey70",xlab="Coefficient",main="Edge")#
hist(Bregion[,3],breaks = seq(minx,maxx,length.out=40), col="grey70",xlab="Coefficient",main="Interior")
for(i in 1:dim(covTau)[1]) {#
	covTau[i,,] = cov2cor(solve(covTau[i,,]))#
}#
par(mfrow = c(2,2))#
hist(covTau[,1,2],breaks = seq(-1,1,length.out=40),col="grey70",main = "Inshore, Edge",xlab="Correlation")#
hist(covTau[,1,3],breaks = seq(-1,1,length.out=40),col="grey70",main = "Inshore, Interior",xlab="Correlation")#
hist(covTau[,2,3],breaks = seq(-1,1,length.out=40),col="grey70",main = "Edge, Interior",xlab="Correlation")
par(mfrow = c(2,2))#
hist(1/sqrt(oneOverCV2),40, col="grey70",main="CV",xlab="Coefficient")#
hist(B[,6],40, col="grey70",main="Gulf (2)",xlab="Coefficient")
x
dim(x)
pdf("Results.pdf")#
par(mfrow = c(2,2))#
hist(1/sqrt(oneOverCV2),40, col="grey70",main="CV",xlab="Coefficient")#
hist(B[,6],40, col="grey70",main="Gulf (2)",xlab="Coefficient")#
hist(B[,13],40, col="grey70",main="Inlet (2)",xlab="Coefficient")#
#
par(mfrow = c(2,2))#
minx = min(c(B[,2],B[,3]))#
maxx = max(c(B[,2],B[,3]))#
hist(B[,2],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Year 2",xlab="Coefficient")#
hist(B[,3],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Year 3", xlim=range(c(B[,2],B[,3])),xlab="Coefficient")#
minx = min(c(B[,4],B[,5]))#
maxx = max(c(B[,4],B[,5]))#
hist(B[,4],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Season 2",xlab="Coefficient")#
hist(B[,5],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Season 3", xlim=range(c(B[,4],B[,5])),xlab="Coefficient")#
#
par(mfrow = c(2,3))#
minx = min(c(B[,7],B[,8],B[,9]))#
maxx = max(c(B[,7],B[,8],B[,9]))#
hist(B[,7],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Winddir 2",xlab="Coefficient")#
hist(B[,8],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Winddir 3",xlab="Coefficient")#
hist(B[,9],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Winddir 4",xlab="Coefficient")#
minx = min(c(B[,10],B[,11],B[,12]))#
maxx = max(c(B[,10],B[,11],B[,12]))#
hist(B[,10],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Windmag 2",xlab="Coefficient")#
hist(B[,11],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Windmag 3",xlab="Coefficient")#
hist(B[,12],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Windmag 4",xlab="Coefficient")#
par(mfrow = c(2,1))#
minx = min(c(Bregion[,2],Bregion[,3]))#
maxx = max(c(Bregion[,2],Bregion[,3]))#
hist(Bregion[,2],breaks = seq(minx,maxx,length.out=40), col="grey70",xlab="Coefficient",main="Edge")#
hist(Bregion[,3],breaks = seq(minx,maxx,length.out=40), col="grey70",xlab="Coefficient",main="Interior")#
for(i in 1:dim(covTau)[1]) {#
	covTau[i,,] = cov2cor(solve(covTau[i,,]))#
}#
par(mfrow = c(2,2))#
hist(covTau[,1,2],breaks = seq(-1,1,length.out=40),col="grey70",main = "Inshore, Edge",xlab="Correlation")#
hist(covTau[,1,3],breaks = seq(-1,1,length.out=40),col="grey70",main = "Inshore, Interior",xlab="Correlation")#
hist(covTau[,2,3],breaks = seq(-1,1,length.out=40),col="grey70",main = "Edge, Interior",xlab="Correlation")
mean = (1 - pred)/pred#
for(i in 1:313) {#
	for(j in 1:3) {#
		mean[,i,j] = mean[,i,j] * oneOverCV2#
	}#
}#
#
allMeans = apply(mean,c(2,3),mean)#
#
d = cbind(d,allMeans)#
boxplot(c(allMeans) ~ sort(rep(1:3,313)),outline=FALSE,col="grey70",names=c("Inshore","Edge","Interior"),ylab="Mean birds (for average survey)")
dev.off()
getwd()
pdf("Results.pdf")#
par(mfrow = c(2,2))#
hist(1/sqrt(oneOverCV2),40, col="grey70",main="CV",xlab="Coefficient")#
hist(B[,6],40, col="grey70",main="Gulf (2)",xlab="Coefficient")#
hist(B[,13],40, col="grey70",main="Inlet (2)",xlab="Coefficient")#
#
par(mfrow = c(2,2))#
minx = min(c(B[,2],B[,3]))#
maxx = max(c(B[,2],B[,3]))#
hist(B[,2],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Year 2",xlab="Coefficient")#
hist(B[,3],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Year 3", xlim=range(c(B[,2],B[,3])),xlab="Coefficient")#
minx = min(c(B[,4],B[,5]))#
maxx = max(c(B[,4],B[,5]))#
hist(B[,4],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Season 2",xlab="Coefficient")#
hist(B[,5],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Season 3", xlim=range(c(B[,4],B[,5])),xlab="Coefficient")#
#
par(mfrow = c(2,3))#
minx = min(c(B[,7],B[,8],B[,9]))#
maxx = max(c(B[,7],B[,8],B[,9]))#
hist(B[,7],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Winddir 2",xlab="Coefficient")#
hist(B[,8],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Winddir 3",xlab="Coefficient")#
hist(B[,9],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Winddir 4",xlab="Coefficient")#
minx = min(c(B[,10],B[,11],B[,12]))#
maxx = max(c(B[,10],B[,11],B[,12]))#
hist(B[,10],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Windmag 2",xlab="Coefficient")#
hist(B[,11],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Windmag 3",xlab="Coefficient")#
hist(B[,12],breaks = seq(minx,maxx,length.out=40),col="grey70",main="Windmag 4",xlab="Coefficient")#
par(mfrow = c(2,1))#
minx = min(c(Bregion[,2],Bregion[,3]))#
maxx = max(c(Bregion[,2],Bregion[,3]))#
hist(Bregion[,2],breaks = seq(minx,maxx,length.out=40), col="grey70",xlab="Coefficient",main="Edge")#
hist(Bregion[,3],breaks = seq(minx,maxx,length.out=40), col="grey70",xlab="Coefficient",main="Interior")#
for(i in 1:dim(covTau)[1]) {#
	covTau[i,,] = cov2cor(solve(covTau[i,,]))#
}#
par(mfrow = c(2,2))#
hist(covTau[,1,2],breaks = seq(-1,1,length.out=40),col="grey70",main = "Inshore, Edge",xlab="Correlation")#
hist(covTau[,1,3],breaks = seq(-1,1,length.out=40),col="grey70",main = "Inshore, Interior",xlab="Correlation")#
hist(covTau[,2,3],breaks = seq(-1,1,length.out=40),col="grey70",main = "Edge, Interior",xlab="Correlation")#
mean = (1 - pred)/pred#
for(i in 1:313) {#
	for(j in 1:3) {#
		mean[,i,j] = mean[,i,j] * oneOverCV2#
	}#
}#
#
allMeans = apply(mean,c(2,3),mean)#
par(mfrow = c(1,1))#
d = cbind(d,allMeans)#
boxplot(c(allMeans) ~ sort(rep(1:3,313)),outline=FALSE,col="grey70",names=c("Inshore","Edge","Interior"),ylab="Mean birds (for average survey)")#
#
dev.off()
dim(B)
apply(B,2,mean)
apply(B,2,mean), apply(B,2,sd)
cbind(apply(B,2,mean), apply(B,2,sd), apply(B,2,quantile,0.025), apply(B,2,quantile,0.975))
round(cbind(apply(B,2,mean), apply(B,2,sd), apply(B,2,quantile,0.025), apply(B,2,quantile,0.975)),3)
xmat
names(x)
x
colnames(x)
round(cbind(apply(B,2,mean), apply(B,2,sd), apply(B,2,quantile,0.025), apply(B,2,quantile,0.975)),3)
round(cbind(apply(Bregion,2,mean), apply(Bregion,2,sd), apply(Bregion,2,quantile,0.025), apply(Bregion,2,quantile,0.975)),3)
dim(CV)
mean(CV)
oneOverCV2
CV = 1/sqrt(oneOverCV2)
B = CV
c(mean(CV),sd(CV),quantile(CV,c(0.025,0.975)))
round(c(mean(CV),sd(CV),quantile(CV,c(0.025,0.975))))
round(c(mean(CV),sd(CV),quantile(CV,c(0.025,0.975))),3)
